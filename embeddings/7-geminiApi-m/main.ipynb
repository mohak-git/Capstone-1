{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864a9cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from google import genai\n",
    "import os\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db6ea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "INPUT_CSV = \"../../data/Sarcasm_Detection.csv\"\n",
    "OUTPUT_CSV = \"sd/embeddings.csv\"\n",
    "INT_OUTPUT_CSV = \"sd/embeddings_int.csv\"\n",
    "\n",
    "BATCH_SIZE = 99\n",
    "SLEEP_SECONDS = 60.0\n",
    "MODEL_NAME = \"gemini-embedding-001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffbd447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Input & Resume\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "if \"headline\" not in df.columns:\n",
    "    raise ValueError(\"Input CSV must have 'headline' column\")\n",
    "\n",
    "headlines = df.iloc[:, 1:][\"headline\"].tolist()\n",
    "\n",
    "if os.path.exists(OUTPUT_CSV):\n",
    "    out_df = pd.read_csv(OUTPUT_CSV, header=0)\n",
    "    already = len(out_df)\n",
    "    print(f\"Found {already} embeddings in {OUTPUT_CSV}\")\n",
    "else:\n",
    "    already = 0\n",
    "    print(\"Starting fresh, no existing embeddings file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e736bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed\n",
    "def embed_batch(texts: list[str]) -> list[list[float]]:\n",
    "    response = client.models.embed_content(\n",
    "        model=MODEL_NAME,\n",
    "        contents=texts,\n",
    "    )\n",
    "\n",
    "    embeddings = [emb.values for emb in response.embeddings]\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3043b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batching, embedding, incremental saving\n",
    "\n",
    "if already != df.shape[0]:\n",
    "    for start in range(already, len(headlines), BATCH_SIZE):\n",
    "        batch = headlines[start : start + BATCH_SIZE]\n",
    "        try:\n",
    "            tm = time.time()\n",
    "            emb_batch = embed_batch(batch)\n",
    "            print(f\"Embeddings received in {time.time() - tm:.2f}s.\")\n",
    "        except Exception as e:\n",
    "            print(\"Error embedding batch at start\", start, \":\", e)\n",
    "            raise\n",
    "\n",
    "        # Append batch to file\n",
    "        pd.DataFrame(emb_batch).to_csv(\n",
    "            OUTPUT_CSV,\n",
    "            mode=\"a\",\n",
    "            header=False if start > 0 or already > 0 else True,\n",
    "            index=False,\n",
    "        )\n",
    "\n",
    "        print(f\"Processed batch {start}-{start + len(emb_batch)}\")\n",
    "\n",
    "        # Respect rate limit\n",
    "        for remaining in range(int(SLEEP_SECONDS), 0, -1):\n",
    "            print(f\"  ...waiting {remaining}s\", end=\"\\r\", flush=True)\n",
    "            time.sleep(1)\n",
    "        print()\n",
    "\n",
    "print(\"Done embedding all.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040d2d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all embeddings to integar embeddings\n",
    "emb_df = out_df.copy()\n",
    "\n",
    "\n",
    "# Shift to strictly positive\n",
    "def shift_to_positive(embeddings, eps=1e-6):\n",
    "    min_val = embeddings.values.min()\n",
    "    shift = -min_val + eps\n",
    "    return embeddings + shift\n",
    "\n",
    "\n",
    "positive_embeddings = shift_to_positive(emb_df)\n",
    "\n",
    "\n",
    "# Scale + Round to Integers\n",
    "def scale_and_round(embeddings, desired_max=15565):\n",
    "    max_val = embeddings.values.max()\n",
    "    scale = desired_max / max_val\n",
    "    return np.round(embeddings * scale).astype(int)\n",
    "\n",
    "\n",
    "int_embeddings = scale_and_round(positive_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2d5153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "emb_cols = [f\"emb_{i}\" for i in range(int_embeddings.shape[1])]\n",
    "int_embeddings.to_csv(INT_OUTPUT_CSV, index=False)\n",
    "\n",
    "\n",
    "print(f\"Saved integer embeddings to {INT_OUTPUT_CSV}\")\n",
    "print(\"Integer embeddings shape:\", int_embeddings.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
